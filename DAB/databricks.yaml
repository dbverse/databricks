# databricks.yaml
# Bundle definition for Retail DLT Pipeline.

bundle:
  name: retail-dlt-pipeline

resources:
  pipelines:
    retail_raw_ingestion_pipeline:
      name: ${bundle.target}-retail-raw-ingestion-pipeline # Pipeline name in Databricks UI
      # storage_location removed: DLT manages storage location automatically with Unity Catalog target.
      libraries:
        - file: src/retail_raw_dlt_pipeline.py # Path to DLT pipeline script
      target: raw # Tables published to 'raw' schema in Unity Catalog
      catalog: users # Explicitly set Unity Catalog catalog, as per your reference
      serverless: true # Explicitly enable serverless compute for the DLT pipeline
      continuous: false # Batch pipeline
      development: true # Set to false for production deployments
      photon: true # Enabled Photon, essential for Serverless DLT in most configurations
      channel: CURRENT # Use latest DLT runtime

  jobs:
    run_retail_dlt_job:
      name: ${bundle.target}-run-retail-raw-dlt-job
      tasks:
        - task_key: run_dlt_pipeline
          pipeline_task:
            pipeline_id: ${resources.pipelines.retail_raw_ingestion_pipeline.id} # Reference to DLT pipeline
      # Schedule block remains removed as requested earlier.

targets:
  dev:
    workspace:
      host: https://dbc-90c2efcc-0370.cloud.databricks.com/ # Your Databricks workspace URL
